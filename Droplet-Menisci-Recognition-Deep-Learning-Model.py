# -*- coding: utf-8 -*-
"""shared-with Moonlab-EWOD_ML-Unet-Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YRmdTu8lFOxvbKYpwwgxxCvoBuabstHC
"""

import numpy as np
import matplotlib.pyplot as plt
import os, shutil

# Imported for image viewing
from PIL import Image
from IPython.display import display
import tensorflow as tf

# # Make only selected GPUs visible
# os.environ["CUDA_VISIBLE_DEVICES"]="3"

import glob
import random
from keras.models import *

from keras.layers import Input, Concatenate, Conv2D, MaxPooling2D
# from keras.layers import Input, merge, Conv2D, MaxPooling2D
from keras.layers import UpSampling2D, Dropout, Cropping2D, Concatenate, BatchNormalization
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras import backend as keras
from sklearn.model_selection import train_test_split

#from keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.utils import img_to_array, load_img

from google.colab import drive
drive.mount('/content/drive')

#original: image_dir = '/content/images' # change according to where images are stored
image_dir = '/content/drive/MyDrive/images-3/0' # change according to where images are stored

#original: labels_dir = '/content/drive/My Drive/masks' # change according to where masks are stored
labels_dir = '/content/drive/MyDrive/masks' # change according to where masks are stored

height = 512
width = 512
color_space = "grayscale"

n_channels = 1

# Get parameters of the input and output from images and labels
images = glob.glob(image_dir+'/*')
labels = glob.glob(labels_dir+'/*')
print(labels)

n_images = len(images)
n_classes = len(labels)

print('Number of images : ', n_images)
print('Number of channels : ', n_channels)
print('Number of classes :', n_classes)
print('Image height : ', height)
print('Image width :', width)

data_images = np.ndarray((n_images, height, width, n_channels), dtype=np.uint8)
data_labels = np.ndarray((n_images, height, width, n_classes), dtype=np.uint8)

print(data_images.shape)
print(data_labels.shape)

idx = 0
for i in images:

    # Read image
    fn = i

    # Convert to desired color space
    img = load_img(fn, color_mode = color_space, target_size=(height, width))
    img = img_to_array(img)

    # Put in the data_images array
    data_images[idx] = img

    # Look for labels for this image, read and put in the data_labels array
    # Take note that this starts from 0 and goes to n. The labels must be labeled in this sense.
    for j in range(0, n_classes):

        img_fn = fn.split('/')[-1]

        label_fn = labels_dir+'/'+str(j)+'/'+img_fn
        # label_fn = labels_dir+'/'+str(1)+'/'+img_fn # fixed because we started with 1
        #print('Our label fn is:')
        #print(label_fn)

        # If file label_fn exists read
        if os.path.exists(label_fn):

            label = load_img(label_fn, color_mode = "grayscale", target_size=(height, width))
            label = img_to_array(label)
            label = np.reshape(label, (height, width))

            data_labels[idx,:,:,j] = label

        else:
            data_labels[idx,:,:,j] = 0

    idx = idx + 1

data_images = data_images.astype('float32')
data_labels = data_labels.astype('float32')
data_images /= 255
data_labels /= 255
data_labels[data_labels > 0.5] = 1
data_labels[data_labels <= 0.5] = 0
#data_images_train, data_images_test, data_labels_train, data_labels_test = train_test_split(data_images, data_labels, test_size = 0.2, random_state =42)
#print(len(data_images_train))
#print(len(data_images_test))
#print((len(data_labels_train)))
#print(len(data_labels_test))


# Reading in image
# print(data_labels[0])
# img = Image.fromarray(data_labels[0][1:2], 'L')

# Plot sample labels and images

fig, axs = plt.subplots(2, 2,  figsize=(20,10))

axs[0, 0].imshow(data_images[0])
axs[0, 1].imshow(data_images[1,:,:,0],'gray')
# axs[0, 2].imshow(data_images[2,:,:,0],'gray')
# axs[0, 3].imshow(data_images[3,:,:,0],'gray')
# axs[0, 4].imshow(data_images[4,:,:,0],'gray')
# axs[0, 5].imshow(data_images[5,:,:,0],'gray')
# axs[0, 6].imshow(data_images[6,:,:,0],'gray')
# axs[0, 7].imshow(data_images[7,:,:,0],'gray')

axs[1, 0].imshow(data_labels[0])
axs[1, 1].imshow(data_labels[1,:,:,0],'gray')
# axs[1, 2].imshow(data_labels[2,:,:,0],'gray')
# axs[1, 3].imshow(data_labels[3,:,:,0],'gray')
# axs[1, 4].imshow(data_labels[4,:,:,0],'gray')
# axs[1, 5].imshow(data_labels[5,:,:,0],'gray')
# axs[1, 6].imshow(data_labels[6,:,:,0],'gray')
# axs[1, 7].imshow(data_labels[7,:,:,0],'gray')


plt.show(block=True)

#Data Augmentation
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
        #rescale=1./255,
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        #brightness=2,
        #hue=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode='nearest'
        )
#image_mask = np.concatenate([data_images, data_labels], axis=3)
j=1
Number_agumentation=4
for i in range(len(data_images)):
 for seed in range(Number_agumentation):
    if seed==0:
      if j==1:
        data_images_augmented=np.reshape(data_images[i,:,:,0],(1,512,512,1))
        data_masks_augmented=np.reshape(data_labels[i,:,:,0],(1,512,512,1))
        j=0
      else:
        data_images_augmented=np.append(data_images_augmented,np.reshape(data_images[i,:,:,0],(1,512,512,1)), axis=0)
        data_masks_augmented=np.append(data_masks_augmented,np.reshape(data_labels[i,:,:,0],(1,512,512,1)), axis=0)
    train_image_generator = train_datagen.flow(np.reshape(data_images[i,:,:,0],(1,512,512,1)), seed=seed, batch_size = 1)
    train_mask_generator = train_datagen.flow(np.reshape(data_labels[i,:,:,0],(1,512,512,1)), seed=seed, batch_size = 1)
    data_images_augmented=np.append(data_images_augmented,train_image_generator[0], axis=0)
    data_masks_augmented=np.append(data_masks_augmented,train_mask_generator[0], axis=0)
print(data_images_augmented.shape)
print(data_masks_augmented.shape)
print('Number of augmented images (total number of training data) : ', len(data_images_augmented))
#train_data=zip(train_image_generator, train_mask_generator)
#train_image_generator = train_datagen.flow(np.reshape(data_images[0,:,:,0],(1,512,512,1)), np.reshape(data_labels[0,:,:,0],(1,512,512,1)), batch_size = 1)

#train_mask_generator = train_datagen.flow(np.reshape(data_labels[0,:,:,0],(1,512,512,1)), batch_size = 1)
#print(train_image_generator[0].shape)
#print(train_mask_generator[0].shape)

# Plot sample augmented labels and images

fig, axs = plt.subplots(5, 2,  figsize=(100,50))
image_index=97
number_of_augmentation=4
axs[0 , 0].imshow(data_images_augmented[(image_index-1)*number_of_augmentation])
axs[0, 1].imshow(data_masks_augmented[(image_index-1)*number_of_augmentation])

axs[1 , 0].imshow(data_images_augmented[(image_index-1)*number_of_augmentation+1])
axs[1, 1].imshow(data_masks_augmented[(image_index-1)*number_of_augmentation+1])

axs[2 , 0].imshow(data_images_augmented[(image_index-1)*number_of_augmentation+2])
axs[2, 1].imshow(data_masks_augmented[(image_index-1)*number_of_augmentation+2])

axs[3 , 0].imshow(data_images_augmented[(image_index-1)*number_of_augmentation+3])
axs[3, 1].imshow(data_masks_augmented[(image_index-1)*number_of_augmentation+3])

axs[4 , 0].imshow(data_images_augmented[(image_index-1)*number_of_augmentation+4])
axs[4, 1].imshow(data_masks_augmented[(image_index-1)*number_of_augmentation+4])

plt.show(block=True)

# Don't need to run
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
    plt.tight_layout()
    plt.show()

augmented_images = [train_image_generator[0][0]]
plotImages(augmented_images)
print(augmented_images[0].shape)
augmented_images2 = [train_mask_generator[0][0]]
plotImages(augmented_images2)
print(augmented_images2[0].shape)
#augmented_images = [train_mask_generator[0][0][0] for i in range(5)]
#plotImages(augmented_images)

from sklearn.utils import shuffle
train = shuffle('train')

# create validation set
data_images_training, data_labels_training, data_images_test, data_labels_test = train_test_split(data_images, data_labels, test_size = 0.2,random_state=42)
(data_images_training.shape, data_images_test.shape), (data_labels_training.shape, data_labels_test.shape)

# Matin edit
n_samples = 3
for j in range(0,n_samples):

    test_image_idx = random.randint(0,n_images-1)

    f = plt.figure()

    f.add_subplot(1,n_classes+1, 1) # image forst
    plt.imshow(data_images[test_image_idx,:,:,0],'gray')

    # Loop over classes
    for k in range(0,n_classes):

        f.add_subplot(1,n_classes+1, k+2)
        plt.imshow(data_labels[test_image_idx,:,:,k],'gray')


    plt.show(block=True)

# Plot sample labels and images (Duplicate of "Matin Edit", previous cell)
n_samples = 3
for j in range(0,n_samples):

   test_image_idx = random.randint(0,n_images-1)

   f = plt.figure()

   f.add_subplot(1,n_classes+1, 1) # image forst
   plt.imshow(data_images[test_image_idx,:,:,0],'gray')

    # Loop over classes
   for k in range(0,n_classes):

        f.add_subplot(1,n_classes+1, k+2)
        plt.imshow(data_labels[test_image_idx,:,:,k],'gray')


   plt.show(block=True)

# Define the U-net network

def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):
    if depth > 0:
        n = conv_block(m, dim, acti, bn, res)
        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)
        m = level_block(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)
        if up:
            m = UpSampling2D()(m)
            m = Conv2D(dim, 2, activation=acti, padding='same')(m)
        else:
            m = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)
        n = Concatenate()([n, m])
        m = conv_block(n, dim, acti, bn, res)
    else:
        m = conv_block(m, dim, acti, bn, res, do)
    return m

def conv_block(m, dim, acti, bn, res, do=0):
    n = Conv2D(dim, 3, activation=acti, padding='same')(m)
    n = BatchNormalization()(n) if bn else n
    n = Dropout(do)(n) if do else n
    n = Conv2D(dim, 3, activation=acti, padding='same')(n)
    n = BatchNormalization()(n) if bn else n
    return Concatenate()([m, n]) if res else n

def unet(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu',
         dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=True):

    i = Input(shape=img_shape)
    o = level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)
    o = Conv2D(out_ch, 1, activation='sigmoid')(o)

    model = Model(inputs=i, outputs=o)
    #negar# model.compile(optimizer = Adam(lr = 1e-5), loss = 'categorical_crossentropy', metrics = ['accuracy'])
    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['mse'])
    #matin #model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])
## loss = 'binary_crossentropy'  ---> the loss function honson used.
    return model

model = unet((height, width, n_channels),
             out_ch=1,
             start_ch=64,
             depth=4,
             inc_rate=2.,
             activation="relu",
             dropout=0.5,
             batchnorm=False,
             maxpool=True,
             upconv=True,
             residual=True)
model.summary()

## activation='relu' -----> the activation function honson used.

from keras.callbacks import ModelCheckpoint

#model_checkpoint = ModelCheckpoint("EwodMlAug2024.hdf5", monitor='loss', verbose=1, save_best_only=True)
print('Fitting model...')
history = model.fit(data_images_augmented,
          data_masks_augmented,
          batch_size=4,
          epochs=100,
          verbose=1,
          #validation_data=(data_images_test, data_labels_test),
          validation_split=0.3,
          shuffle=True,
          )

#model_file = "/content/drive/My Drive/Colab Notebooks/model_file"
#print("Saving model file in ", model_file)
#model.save(model_file)

from keras.callbacks import ModelCheckpoint

training_data=image_augmentation(data_images, data_labels)
#model_checkpoint = ModelCheckpoint('EwodMlAug2024.hdf5', monitor='loss', verbose=1, save_best_only=True)
print('Fitting model...')
history = model.fit(training_data,
                    epochs=50,
                    shuffle=True,
                    )

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

# list all data in history
#print(history.history.keys())

# summarize history for accuracy
plt.plot(history.history['mse'])
plt.plot(history.history['val_mse'])
plt.title('model mse')
plt.ylabel('mse')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Validation

inference_model = unet((height, width, n_channels),
             out_ch=1,
             start_ch=64,
             depth=4,
             inc_rate=2.,
             activation="relu",
             dropout=0.5,
             batchnorm=False,
             maxpool=True,
             upconv=True,
             residual=True)
inference_model.load_weights('/content/drive/MyDrive/NegarNet_May28.hdf5')
#inference_model.load_weights('/content/drive/My Drive/Colab Notebooks/unet.hdf5')

# Runs Inference
n =3

test_image_idx = random.randint(0,len(data_images_augmented))
print(test_image_idx)
test_image = data_images_augmented[test_image_idx]

test_data = np.ndarray((n, height, width, n_channels), dtype=np.uint8)
#img = load_img(test_image, color_mode = color_space, target_size=(height, width))

img = test_image

test_data[0] = img

# Convert to float and normalize
#test_data = test_data.astype('float32')
#test_data /= 255

print("running test inference")
img_mask = model.predict(np.reshape(img, (1,512,512,1)), batch_size=1, verbose=1)
print(img_mask.shape)
print("test ok")

# Loads and tests random image from trained model

import math

img_per_row = 3
n_rows = math.ceil(n_classes/img_per_row) + 1

plt.rcParams["figure.figsize"] = (10,20)
plt.title('Image')
plt.imshow(test_data[0,:,:,0], "gray")
plt.show()

#Threshold
#threshold = 0.5
#img_mask[img_mask > threshold] = 1
#img_mask[img_mask <= threshold] = 0

print('Model output')

plt.rcParams["figure.figsize"] = (15,30)
f1 = plt.figure()

# Loop over classes
print('Our n classes is ', n_classes)
for k in range(0,n_classes):

    f1.add_subplot(n_rows, img_per_row, k+1)
    plt.imshow(img_mask[0,:,:,k])

plt.tight_layout()
plt.show()


print('Ground truth')

plt.rcParams["figure.figsize"] = (15,30)
f2 = plt.figure()

# Loop over classes
for k in range(0,n_classes):

    f2.add_subplot(n_rows, img_per_row, k+1)
    plt.imshow(data_masks_augmented[test_image_idx,:,:,k],'gray')

plt.tight_layout()
plt.show()

type(img_mask[0,:,:,k])

import collections
import json
import os
import uuid
import gc

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from PIL import Image, ImageDraw
import tifffile as tiff
import seaborn as sns
import tensorflow as tf
from tqdm.notebook import tqdm

from skimage.measure import label, regionprops
import cv2

def DICE_COE(mask1, mask2):
    intersect = np.sum(mask1*mask2)
    fsum = np.sum(mask1)
    ssum = np.sum(mask2)
    dice = (2 * intersect ) / (fsum + ssum)
    dice = np.mean(dice)
    dice = round(dice, 3) # for easy reading
    return dice

DICE_COE(test_data[0,:,:,0],img_mask[0,:,:,k])

image1 = image1[0][0].transpose(1, 2, 0)
plt.figure(figsize=(10, 10))
plt.imshow(image1)
plt.title("Random Image of Kidney Tissue", size=15)
plt.show()

img_mask_RAO_1_mod1=img_mask[0,:,:,0].copy()
img_mask_RAO_1_mod1[img_mask_RAO_1_mod1 > 0.5] = 1
img_mask_RAO_1_mod1[img_mask_RAO_1_mod1 <= 0.5] = 0


#img_mask_RAO_2_mod1=img_mask[1,:,:,0].copy()
#img_mask_RAO_2_mod1[img_mask_RAO_2_mod1 > 0.5] = 1
#img_mask_RAO_2_mod1[img_mask_RAO_2_mod1 <= 0.5] = 0


#img_mask_RAO_3_mod1=img_mask[2,:,:,0].copy()
#img_mask_RAO_3_mod1[img_mask_RAO_3_mod1 > 0.5] = 1
#img_mask_RAO_3_mod1[img_mask_RAO_3_mod1 <= 0.5] = 0


fig, axs = plt.subplots(2, 3,  figsize=(20,10))


axs[0, 0].imshow(test_data[0,:,:,0], 'gray')
axs[0, 1].imshow(test_data[1,:,:,0],'gray')
axs[0, 2].imshow(test_data[2,:,:,0],'gray')
axs[1, 0].imshow(img_mask_RAO_1_mod1)
axs[1, 1].imshow(img_mask_RAO_2_mod1)
axs[1, 2].imshow(img_mask_RAO_3_mod1)

import matplotlib.pyplot as plt
from skimage.morphology import skeletonize
from scipy import ndimage

img_mask_RAO_1_lee = skeletonize(img_mask_RAO_1_mod1, method='lee')

fullcath_RAO_2=np.transpose(np.nonzero(img_mask_RAO_1_lee)) #img_mask_RAO_2
fullcath_RAO_2_2=np.where(img_mask_RAO_1_lee !=0) #img_mask_RAO_

all_x_RAO_2=[i for i in fullcath_RAO_2_2[1]]
all_y_RAO_2=[i for i in fullcath_RAO_2_2[0]]

cent_entire_cath_RAO_1=ndimage.measurements.center_of_mass(img_mask_RAO_1_lee)
print(cent_entire_cath_RAO_1)


tst_second_POI=[j for i,j in fullcath_RAO_2 if i==int(cent_entire_cath_RAO_1[0])]
print(tst_second_POI)
avg_tst_second_POI=np.mean(tst_second_POI)
print(avg_tst_second_POI)

all_tst_third_POI = np.array(sorted(fullcath_RAO_2, key = lambda i: i[0], reverse = True))[0]
print(all_tst_third_POI)

#CASE 2 PAIR 1
fig = plt.figure(figsize =(10, 10))
ax=plt.subplot(1, 1, 1)


ax.plot(all_x_RAO_2, all_y_RAO_2, 'yd')

# ax.plot(img_mask_RAO_1_cent[1],img_mask_RAO_1_cent[0],'bd')
# ax.plot(avg_tst_second_POI,int(cent_entire_cath_RAO_1[0]), 'rx',markersize=15)

ax.plot(210,280, 'rx',markersize=15)
# ax.plot(all_tst_third_POI[1],all_tst_third_POI[0], 'bx',markersize=15)

ax.plot(200,380, 'bx',markersize=15)

ax.plot(455,270, 'bx',markersize=15)
ax.plot(210,157, 'bx',markersize=15)

ax.plot(5,250, 'bx',markersize=15)

plt.gca().invert_yaxis()
plt.xlim(0,512)
plt.ylim(512,0)

test_1=test_data[0,:,:,0].copy()
# test_1[img_mask_RAO_3_mod1 > 0.5]=0
# test_1 +=img_mask_RAO_1_mod1
#CASE 2 PAIR 1
fig = plt.figure(figsize =(15, 15))
ax=plt.subplot(1, 1, 1)
ax.imshow(test_1,'gray')
ax.plot(210,280, 'rx',markersize=15)
# ax.plot(all_tst_third_POI[1],all_tst_third_POI[0], 'bx',markersize=15)

ax.plot(200,380, 'bx',markersize=15)

ax.plot(455,270, 'bx',markersize=15)
ax.plot(210,157, 'bx',markersize=15)

ax.plot(5,250, 'bx',markersize=15)

img_mask[0,:,:,0]=img_mask[0,:,:,0]*255
im=img_mask[0,:,:,0].astype(np.uint8)
results=np.argwhere(im !=0)
x=[row[1] for row in results]
y=[col[0] for col in results]

plt.imshow(img_mask[0,:,:,0])

x=[j for j in x if j<400 and j>20]
print(min(x))
print(max(x))
y=[i for i in y if i<400 and i>20]
print(min(y))
print(max(y))
xcent=(max(x)-min(x))+ min(x)
ycent=(max(y)-min(y))+min(y)
print('The Exact Coordinate for the Catheter Tip is: ' + str((xcent, ycent)))
#print(ycent)



print(len(x))
print(len(y))

plt.scatter(x,y)

import cv2
from skimage.filters import threshold_otsu
from skimage import filters
from skimage import exposure
val = filters.threshold_otsu(img_mask[0,:,:,0])
testosee=img_mask[0,:,:,0] < val
testosee=testosee*255
imval=testosee.astype(np.uint8)
resultsval=np.argwhere(imval !=0)
xval=[row[1] for row in resultsval]
yval=[col[0] for col in resultsval]

#plt.imshow(img_mask[0,:,:,0])




#testosee=img_mask[0,:,:,k] < val

plt.scatter(xval,yval)

#print(len(x))
#print(len(y))
print(min(x))
print(max(x))
print(min(y))
print(max(y))
print(x[0])

for i in x:
  if i>0:
      continue;
for j in y:
  if j>0:
      continue;
plt.scatter(i,j)

train_img_fnames = os.listdir( train_images_dir )
train_msk_fnames = os.listdir( train_masks_dir )

print(train_img_fnames[:12])
print(train_msk_fnames[:12])

train_image_generator = train_datagen.flow_from_directory(
train_images_dir,
batch_size = 12)

train_mask_generator = train_datagen.flow_from_directory(
train_masks_dir,
batch_size = 12)

val_image_generator = val_datagen.flow_from_directory(
validation_images_dir,
batch_size = 8)


val_mask_generator = val_datagen.flow_from_directory(
validation_masks_dir,
batch_size = 8)



train_generator = zip(train_image_generator, train_mask_generator)
val_generator = zip(val_image_generator, val_mask_generator)

#x=[i for i in x if 200>i and i>50]
#y=[i for i in y if 200>i and i>50]
plt.scatter(x,y)

base_dir= '/content/drive/My Drive/Colab Notebooks/dataset'


train_dir=os.path.join(base_dir, 'train')
validation_dir= os.path.join(base_dir, 'validation')

#training
train_images_dir=os.path.join(train_dir, 'images')
train_masks_dir=os.path.join(train_dir, 'masks')

 # validation
validation_images_dir=os.path.join(validation_dir, 'images')
validation_masks_dir=os.path.join(validation_dir, 'masks')

DATA_PATH = '/content/drive/My Drive/Colab Notebooks/dataset'
FRAME_PATH = DATA_PATH+'/images'
MASK_PATH = DATA_PATH+'/masks'

# Create folders to hold images and masks

folders = ['train_frames', 'train_masks', 'val_frames', 'val_masks', 'test_frames', 'test_masks']


for folder in folders:
  os.makedirs(DATA_PATH + folder)


# Get all frames and masks, sort them, shuffle them to generate data sets.

all_frames = os.listdir(FRAME_PATH)
all_masks = os.listdir(MASK_PATH)

for k in range(0,n_classes):
    outputest=cv2.cvtColor(img_mask[0,:,:,k], cv2.COLOR_BGR2RGB)
    gray=cv2.cvtColor(outputest, cv2.COLOR_RGB2GRAY)
    plt.imshow(gray, cmap='gray')
    plt.show()
print('READY')

from skimage.segmentation import slic
from skimage.color import label2rgb
from skimage.color import rgb2gray

for k in range(0,n_classes):
    f1.add_subplot(n_rows, img_per_row, k+1)
   # plt.imshow(img_mask[0,:,:,k], cmap='gray')
    thresh=threshold_otsu(img_mask[0,:,:,k])
    binary_global=img_mask[0,:,:,k]>thresh
    grayscale = rgb2gray(binary_global)
    plt.imshow(grayscale)
    blk=[]
    for i in grayscale:
        if (i==10).all():
            blk.append(i)
print(blk)


print(blk.count('True'))
plt.tight_layout()
plt.show()

for k in range(0,n_classes):
    outputest=cv2.cvtColor(img_mask[0,:,:,k], cv2.COLOR_BGR2RGB)
    gray=cv2.cvtColor(outputest, cv2.COLOR_RGB2GRAY)
    # Set threshold level
    threshold_level = 100

    # Find coordinates of all pixels below threshold
    coords = np.column_stack(np.where(gray < threshold_level))
    coorlist=list(coords)

print(coords)
print(len(coords))

np.set_printoptions(threshold=False)

# Create mask of all pixels lower than threshold level
mask = gray < threshold_level

# Color the pixels in the mask
image[mask] = (204, 119, 0)

cv2.imshow('image', image)
cv2.waitKey()

import cv2
from skimage.filters import threshold_otsu
from skimage import filters
from skimage import exposure
# to be able to turn this off, by this: printing full numpy array, ""  np.set_printoptions(threshold=False)  ""

for k in range(0,n_classes):
    outputest=cv2.cvtColor(img_mask[0,:,:,k], cv2.COLOR_BGR2RGB)
    gray=cv2.cvtColor(outputest, cv2.COLOR_RGB2GRAY)
    val = filters.threshold_otsu(gray)
    black = [0,0,0]

    #plt.imshow(img_mask[0,:,:,k] < val, cmap='gray')
    #img3inv=cv2.bitwise_not(gray)
    img3iblur= cv2.medianBlur(gray,5)
    ret,thresh = cv2.threshold(img3iblur,255,0,0)
    plt.imshow(img3iblur)

    #contours,hierachy= cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
   # for i in coortest:
    #    coords = np.column_stack(np.where(i))
    #print(coords)




print(img_mask[0,:,:,k].shape)
print(512*512)
print(coortest)
print(len(coords))
plt.show()

import cv2
from skimage.filters import threshold_otsu
from skimage import filters
from skimage import exposure
for k in range(0,n_classes):
    val = filters.threshold_otsu(img_mask[0,:,:,k])
    hist, bins_center = exposure.histogram(img_mask[0,:,:,k])


    plt.figure(figsize=(20, 4))
    plt.subplot(131)
    plt.imshow(img_mask[0,:,:,k], cmap='gray', interpolation='nearest')
    plt.axis('off')
    plt.subplot(132)
    plt.imshow(img_mask[0,:,:,k] < val, cmap='gray', interpolation='nearest')
    plt.axis('off')
    plt.subplot(133)
    plt.plot(bins_center, hist, lw=3)
    plt.axvline(val, color='k', ls='--')
    testtest=list(img_mask[0,:,:,k] < val)
    blk=[]
    for i in testtest:
        if (i==0).all():
            blk.append(i)

plt.show()
print(type(testtest))
print(len(blk))
print(blk)

import cv2
from skimage.filters import threshold_otsu
from skimage import filters
from skimage import exposure
for k in range(0,n_classes):
    f1.add_subplot(n_rows, img_per_row, k+1)
   # plt.imshow(img_mask[0,:,:,k], cmap='gray')
    thresh=threshold_otsu(img_mask[0,:,:,k])
    binary_global=img_mask[0,:,:,k]>thresh
    plt.imshow(binary_global)


plt.tight_layout()
plt.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

val_datagen = ImageDataGenerator(rescale=1./255)

for data_batch, labels_batch in train_generator:
  print('data batch shape:', data_batch.shape)
  print('labels batch shape:', labels_batch.shape)
  break

image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

train_data_gen = image_gen_train.flow_from_directory(batch_size=20,
                                                     directory=train_dir,
                                                     shuffle=True,
                                                     target_size=(512,512),
                                                     class_mode='binary')


image_gen_val = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

val_data_gen = image_gen_val.flow_from_directory(batch_size=20,
                                                 directory=validation_dir,
                                                 target_size=(521, 521),
                                                 class_mode='binary')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen=ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

datagen=ImageDataGenerator(
    rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

from keras.preprocessing import image

fnames=[os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]
img_path=fnames[3]
img=image.load_img(img_path, target_size=(150, 150))
x=image.img_to_array(img)
x=x.rehape((1,)+x.shape)

i=0
for batch in datagent.flow(x, batch_size=1):
  plt.figure(i)
  imgplot=plt.imshow(image.array_to_img(batch[0]))
  i +=1
  if i % 4 == 0:
    break
plt.show()

print(binary_global.shape)

num_img_tr = len(os.listdir(train_images_dir))
num_masks_tr = len(os.listdir(train_masks_dir))
num_img_val=len(os.listdir(validation_images_dir))
num_masks_val=len(os.listdir(validation_masks_dir))

print('total training images:', num_img_tr)
print('total training masks :', num_masks_tr)

print('total validation images:', num_img_val)
print('total validation masks:', num_masks_val)

# convert to RGB
#image = cv2.cvtColor(binary_global, cv2.COLOR_BGR2RGB)
# convert to grayscale
gray = cv2.cvtColor(binary_global, cv2.COLOR_RGB2GRAY)

_, binary = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)
# show it
plt.imshow(binary, cmap="gray")
plt.show()

from astropy.convolution import Gaussian2DKernel
from photutils.datasets import make_100gaussians_image
from photutils import Background2D, MedianBackground
from photutils import detect_threshold, detect_sources
data = make_100gaussians_image()
bkg_estimator = MedianBackground()
bkg = Background2D(data, (50, 50), filter_size=(3, 3), bkg_estimator=bkg_estimator)
threshold = bkg.background + (2. * bkg.background_rms)

from keras.preprocessing import image
fnames = [os.path.join(train_images_dir) for
          fname in os.listdir(train_images_dir)]
img_path = fnames[3]
img=image.load_img(img_path, target_size=(150,150))
x = image.img_to_array(img)
x = x.reshape((1,)+ x.shape)
i=0
for batch in datagen.flow(x, batch_size=1):
  plt.figure(i)
  imgplot = plt.imshow(image.array_to_img(batch[0]))
  i +=1
  if i % 4 == 0:
    break
plt.show()

for k in range(0,n_classes):
    #plt.imshow(img_mask[0,:,:,k], cmap='gray')
    yx_coords = np.column_stack(np.where(img_mask[0,:,:,k] >= 0))
    print (yx_coords)
    #plt.show()

plt.imshow(img_mask[0,:,:,k])
plt.show()



def process_exactframe_detect(img1):
    """Threshhold exact and useful images and find contours and give pixel corrdinate."""
   # global pixelcoor
    img1inv=cv2.bitwise_not(img1)
    img1iblur= cv2.medianBlur(img1inv,5)
    img1_bgr =cv2.cvtColor(img1inv, cv2.COLOR_GRAY2BGR)
    img1_overlay = img1_bgr.copy()
    markerposLAO =np.zeros(shape=(5,2), dtype=int)
    aa=0
    ret,thresh = cv2.threshold(img1iblur,0,255,0)
    thresh=thresh.astype(np.uint8)
   # thadap = cv2.adaptiveThreshold(img1iblur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)
    contours,hierachy= cv2.findContours(thresh,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for i, c in enumerate(contours):
       area= cv2.contourArea(c)
       if area<400:
            continue
       ellipse = cv2.fitEllipse(c)
       x,y =int(ellipse[0][0]), int(ellipse[0][1])
       cv2.ellipse(img1_overlay, ellipse, (0,255,0), 2,cv2.LINE_AA)
       cv2.circle(img1_overlay,(x,y),3,(0,255,0),12)
       markerposLAO[aa,:]  = (x,y)
       aa +=1
       plt.imshow(img1_overlay,'gray'), plt.title('')
       #pixelcoor=[(markerposLAO[3,0], markerposLAO[3,1]),(markerposLAO[4,0],markerposLAO[4,1]),(markerposLAO[0,0],markerposLAO[0,1]),(markerposLAO[1,0],markerposLAO[1,1]),(markerposLAO[2,0],markerposLAO[2,1])]
    return img1_overlay

for k in range(0,n_classes):
    testresult=process_exactframe_detect(img_mask[0,:,:,k])
plt.imshow(testresult)
plt.show()